{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3_1bIxWayJy"
   },
   "source": [
    "# Seminar 2: Sound Analysis and Synthesis\n",
    "\n",
    "## Acoustic Engineering 2024-2025\n",
    "\n",
    "Gen√≠s Plaja - genis.plaja@upf.edu\n",
    "<br>Adriana Modrego - adriana.modrego@upf.edu\n",
    "<br>Zat Pros - zat.pros01@estudiant.upf.edu\n",
    "__<p>18<sup>th</sup> OCTOBER 2024<p>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YgEbRR3ayJ0"
   },
   "source": [
    "## Instructions for submission\n",
    "\n",
    "Like in the previous seminar session, you will have to submit this *jupyter notebook* with all the answers.\n",
    "\n",
    "__CONSIDERATIONS__:\n",
    "* Comment the code when needed.\n",
    "* **ALL RESPONSES MUST BE JUSTIFIED.** Don't submit a *report* but please justify and discuss your experiments using markdown cells.\n",
    "* **PLEASE DO NOT SEND YOUR GENERATED AUDIOS BUT DO SEND THE EXTERNAL AUDIO FILES YOU USE TO COMPLETE YOUR LAB. OTHERWISE WE WON'T BE ABLE TO EXECUTE IT.**\n",
    "* You can upload files to Collab!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgL7_r3dayJ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4FgyL1HayJ1"
   },
   "source": [
    "## Audio Signal Analysis\n",
    "\n",
    "In this exercise, you will analyze your audio signals containing a single note. By examining their spectrum, you will identify the principal harmonics of the sound. Your task is to document the frequencies and relative amplitudes of the first 8-10 harmonics for further analysis.\n",
    "\n",
    "The **Fast Fourier Transform (FFT)** is an efficient implementation of the Fourier transform used in signal processing. By using the `fft()` function from the NumPy library, we can calculate and visualize the magnitude of the Fourier transform.\n",
    "\n",
    "For example, if we have a signal **xx** in the time domain, i.e., amplitude values, and we want to visualize its spectral components (frequency domain), we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xZ3Xa3sVayJ8",
    "outputId": "2c165953-4883-499c-95f6-31031fd125ed"
   },
   "outputs": [],
   "source": [
    "fs = 8000.0\n",
    "Nfft = 1024 # we define here the size that we want for the FFT\n",
    "tt = np.arange(0, 1, 1.0/fs)\n",
    "f = 50\n",
    "xx = np.sin(2 * np.pi * f * tt)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(tt, xx, 'r'), plt.xlabel('Temps (sec)'), plt.ylabel('Amplitud')\n",
    "\n",
    "# we save the FFT magnitud in zz\n",
    "zz = np.abs(np.fft.fft(xx, n=Nfft))\n",
    "\n",
    "# we create a new figure\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# we generate a vector to define the frequencies axis. Remember that the values of this axis goes from 0 to\n",
    "# the signal sampling frequency in steps of fs/Nfft.\n",
    "xf = np.arange(0, fs, fs/float(Nfft))\n",
    "\n",
    "plt.plot(xf, zz) # we plot the spectrum\n",
    "plt.xlabel('Frequency (Hz)'), plt.ylabel('Energy')\n",
    "\n",
    "# in general we are only interested in half of the spectrum since it is symmetric\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(xf[:int(Nfft/2)], zz[:int(Nfft/2)])\n",
    "plt.xlabel('Frequency (Hz)'), plt.ylabel('Energia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__a) Create a function `FFTvisualize(xx, Nfft, fs)` to visualize the spectrum of your chosen single note sound. (xx will be the signal in the temporal domain and Nfft the size of the FFT). Create a subplot where there are different ranges on the x-axis to see the peaks of the spectrum in more or less detail Use `plt.xlim()` to zoom in to different parts of the plot and explain what you see.__\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFTvisualize(xx, Nfft, fs):\n",
    "    \"\"\"\n",
    "    Visualizes the spectrum of a given signal using FFT.\n",
    "\n",
    "    Parameters:\n",
    "    xx (numpy.ndarray): The input signal in the temporal domain.\n",
    "    Nfft (int): The number of points used in the FFT.\n",
    "    fs (int): The sampling frequency in Hz.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the plot of the spectrum.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__b) Use the `FFTvisualize()` function to analyze the spectral components of the sound you downloaded in a stable part of the signal - for example, the middle part. To do it:__\n",
    "\n",
    "* Read the audio file.\n",
    "* Use `FFTvisualize()` to generate the plot. If you only want to use part of the signal, this is where you should specify it.\n",
    "* Choose a plot axis scale that allows you to see the values well.\n",
    "  \n",
    "__We know that the peaks of the spectrum correspond to the sinusoidal components of the signal. Explain the relationship between these peaks: are they harmonic? how are their amplitudes related?, e.g., are they halved? Do they follow a pattern?__\n",
    "\n",
    "__Remember to note down the frequencies and relative amplitudes of the first 8-10 harmonics and store them in two lists.__\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Synthesis\n",
    "\n",
    "In this exercise, you will synthesize harmonics of a musical note by generating sinusoidal waves based on their frequencies and amplitudes. You will compare the synthesized sound to the original, discussing differences in tonal quality and characteristics. Finally, you will replicate a melody using your synthesized instrument and analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__a) We start by implementing a function `singen()` to easily create a sinusoid. Inputs should be amplitude, frequency, sampling frequency, and phase phi.__\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singen(amplitude, frequency, sampling_frequency, phi):\n",
    "    \"\"\"\n",
    "    Generates a sinusoidal signal based on the given parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    amplitude (float): The amplitude of the sinusoid.\n",
    "    frequency (float): The frequency of the sinusoid in Hz.\n",
    "    sampling_frequency (float): The sampling frequency in Hz.\n",
    "    phi (float): The phase of the sinusoid in radians.\n",
    "\n",
    "    Returns:\n",
    "    sinusoid (numpy.ndarray): The generated sinusoidal signal.\n",
    "    \"\"\"\n",
    "    return sinusoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY7NVBMRayJ-"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__a) Create a `synth(f0)` function that generates a signal with similar characteristics to the signal you just analyzed (your chosen sound).__\n",
    "\n",
    "__Use the `singen()` function from the previous exercise to synthesize the sinusoidal components. The function must receive a single parameter: the fundamental frequency of the sound, $f_0$, in Hz.__\n",
    "\n",
    "_Note: this exercise it is about trying to synthesize a sound similar to the original. To do this, you will need to generate a complex signal (with harmonics) where each component has a frequency and an amplitude that roughly follows the relationships between the values you found in the analysis in the previous section. For example: If you found that the fundamental has frequency 220 and the energy of the spectrum is X, and the first harmonic is 440 with 75% of the energy of the first, you should reflect this when deciding the amplitude of each component in the synthesis._\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth(f0):\n",
    "    \"\"\"\n",
    "    Generates a synthesized signal based on the fundamental frequency and its harmonics.\n",
    "    \n",
    "    Parameters:\n",
    "    f0 (float): The fundamental frequency of the sound in Hz\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    signal (numpy.ndarray): The synthesized audio signal.\n",
    "    \"\"\"\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clp3hZ2MayKB"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "__b) Write in a file the signal generated with the function for a $f_0$ equal to that of the original sound. Compare the synthesized sound with the original sound. Do they look alike? Why? And what's different about them?__\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqFJ4I4IayKB"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "__c) Make a subplot with the spectrum of the original signal and the signal (remember to use only the first half of the spectrum). Compare them and explain the differences you see.__\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCjgZ9HAayKC"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "    \n",
    "__d) By changing the input parameter `f0` of the function that generates the synthetic sound, copy the melody of the sound you chose for the previous seminar. At Least 5 notes have to be in the melody: call the function as many times as the notes you want, concatenate the result, and finally use `IPython.display. Audio()` to play it. You can also export the melody as an audio file.__\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__e) Finally plot the two waveforms and spectrograms and compare.__\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
